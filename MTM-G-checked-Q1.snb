{"metadata":{"name":"MTM-G-checked-Q1","user_save_timestamp":"1190-11-11T11:00:00.000Z","auto_save_timestamp":"19719700-11-11T11:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"customLocalRepo":null,"customRepos":null,"customDeps":null,"customImports":null,"customArgs":null,"customSparkConf":null},"cells":[{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"9265623F82D44A268E1C72C4FD7F48B6"},"cell_type":"code","source":":markdown\n#NamedVector.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res1: String = #NamedVector.scala\n"},{"metadata":{},"data":{"text/markdown":"#NamedVector.scala"},"output_type":"execute_result","execution_count":1,"time":"Took: 2 seconds 210 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"2B8FFFF2610F40BA873138C331219D3E"},"cell_type":"code","source":"\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd.RDD\n//import org.apache.spark.util.Vector\nimport org.apache.spark.mllib.linalg.DenseVector\n//import org.apache.spark.ml.linalg.{Vector, Vectors}\n//import org.apache.spark.mllib.linalg.{Vectors, Vector}\n//package org.lipn.som.global\n\nimport java.util.concurrent.TimeUnit._\nimport org.apache.spark.rdd.RDD\n//import org.apache.spark.util.Vector\nimport scala.concurrent.duration.{FiniteDuration, Duration}\n//import org.lipn.som.som.pointObj\nimport org.apache.spark.util\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.linalg.DenseVector\nimport java.util.concurrent.TimeUnit._\nimport org.apache.spark.rdd.RDD\nimport scala.concurrent.duration.{FiniteDuration, Duration}\nimport org.apache.spark.util\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":2,"time":"Took: 1 second 396 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"7128594164A24452A9A28D1190CCB97D"},"cell_type":"code","source":"//package org.lipn.som.utils\n\n//import org.apache.spark.ml.linalg.{Vector, Vectors}\nimport org.apache.spark.mllib.linalg.DenseVector\n\n\n/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 27/03/13\n * Time: 17:07\n * To change this template use File | Settings | File Templates.\n */\nclass NamedVector(elements: Array[Double], val cls: Int) extends DenseVector(elements) with Serializable {\n  override def toString(): String = {\n    \"#\"+cls+\" \"+super.toString()\n  }\n  def toJSON(clusterId: Int): String = {\n    var str = new StringBuilder\n    str append \"{\"\n    for (i <- 0 until elements.length) {\n      str append \"attr\"+i+\":\"+elements(i)+\", \"\n    }\n    str append \"cls:\\\"\"+cls+\"\\\", \"\n    str append \"clusterId:\"+clusterId\n    str append \"}\\n\"\n    str.toString()\n  }\n}","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.linalg.DenseVector\ndefined class NamedVector\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":3,"time":"Took: 1 second 336 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"2736AD3B4D7749D886A123CA1D209170"},"cell_type":"code","source":":markdown\n#Matrix.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res5: String = #Matrix.scala\n"},{"metadata":{},"data":{"text/markdown":"#Matrix.scala"},"output_type":"execute_result","execution_count":4,"time":"Took: 1 second 845 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"7CDF2C41EAC5425782484B5FC1B9D70B"},"cell_type":"code","source":"//package org.lipn.som.utils\n\n/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 27/03/13\n * Time: 19:10\n * To change this template use File | Settings | File Templates.\n */\nclass Matrix(val elements: Array[Array[Double]]) extends Serializable {\n  //def this(nbRow: Int, nbCol: Int) = this(Array.tabulate(nbRow, nbCol){case (r, c) => r+c})\n  def this(nbElements: Int, initValue: Double) = this(Array.fill(nbElements, nbElements)(initValue))\n\n  def fillRow(row: Int, value: Double) = {elements(row) = Array.fill(elements.length)(value)}\n  def apply(row: Int, col: Int):Double = elements(row)(col)\n\n  def addel(row: Int, col: Int, value: Double) {elements(row)(col) += value}\n\n  def += (other: Matrix): Matrix = {\n    //todo: add length check\n    //if (length != other.length)\n    //  throw new IllegalArgumentException(\"Matrix of different length\")\n    var ans = 0.0\n    var i = 0\n    for (i <- 0 until elements.length) {\n      for (j <- 0 until elements(i).length) {\n        elements(i)(j) += other.elements(i)(j)\n      }\n    }\n    this\n  }\n\n  def /= (other: Matrix): Matrix = {\n    //todo: add length check\n    //if (length != other.length)\n    //  throw new IllegalArgumentException(\"Matrix of different length\")\n    var ans = 0.0\n    var i = 0\n    for (i <- 0 until elements.length) {\n      for (j <- 0 until elements(i).length) {\n        if (other.elements(i)(j) == 0) elements(i)(j) /= Double.MinPositiveValue\n        else elements(i)(j) /= other.elements(i)(j)\n      }\n    }\n    this\n  }\n\n  /*def strRow(rowId: Int): String = {\n    var first = true\n\n    var str = new StringBuilder()\n    str append \"[\"\n    for (x <- elements(rowId)) {\n      if (first) {\n        first = false\n      }\n      else {\n        str append \", \"\n      }\n      str append x\n    }\n    str append \"]\"\n    str.toString()\n  }\n\n  def strCol(colId: Int): String = {\n    var first = true\n\n    var str = new StringBuilder()\n    str append \"[\"\n    for (row <- elements) {\n      if (first) {\n        str append row(colId)\n        first = false\n      }\n      else {\n        str append \", \"\n        str append row(colId)\n      }\n    }\n    str append \"]\"\n    str.toString()\n  }*/\n\n  //override def toString = elements.mkString(\"|\", \" | \", \"|\")\n  override def toString: String = {\n    val str = new StringBuilder()\n    for (row <- elements) {\n      for (elem <- row) {\n        str.append(\" |\").append(\"%.2f\".format(elem))\n      }\n      str.append(\"|\\n\")\n    //elements.foreach{r =>\n      //str append row.mkString(\"|\", \" | \", \"|\")+\"\\n\"\n    }\n    str.toString()\n  }\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"defined class Matrix\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":5,"time":"Took: 1 second 363 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"87E58274AD6345E4B90AF097F294602F"},"cell_type":"code","source":":markdown\n#IO.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res8: String = #IO.scala\n"},{"metadata":{},"data":{"text/markdown":"#IO.scala"},"output_type":"execute_result","execution_count":6,"time":"Took: 1 second 627 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"B842BCF3F492457B8A762B8B3CB174CC"},"cell_type":"code","source":"//package org.lipn.som.utils\n\nimport java.io.File\n\n/**\n * Company : Altic - LIPN\n * User: Tugdual Sarazin\n * Date: 06/06/14\n * Time: 11:48\n */\nobject IO {\n\n  /** Deletes each file or directory (recursively) in `files`.*/\n  def delete(files: Iterable[File]): Unit = files.foreach(delete)\n\n  /** Deletes `file`, recursively if it is a directory. */\n  def delete(file: File)\n  {\n      val deleted = file.delete()\n      if(!deleted && file.isDirectory)\n      {\n        delete(listFiles(file))\n        file.delete\n      }\n  }\n\n  /** Returns the children of directory `dir` that match `filter` in a non-null array.*/\n  def listFiles(filter: java.io.FileFilter)(dir: File): Array[File] = wrapNull(dir.listFiles(filter))\n\n  /** Returns the children of directory `dir` that match `filter` in a non-null array.*/\n  def listFiles(dir: File, filter: java.io.FileFilter): Array[File] = wrapNull(dir.listFiles(filter))\n\n  /** Returns the children of directory `dir` in a non-null array.*/\n  def listFiles(dir: File): Array[File] = wrapNull(dir.listFiles())\n\n  private def wrapNull(a: Array[File]) =\n    if(a == null)\n      new Array[File](0)\n    else\n      a\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"import java.io.File\ndefined object IO\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":7,"time":"Took: 1 second 270 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"328A3B91F45A4B65AFB7357CD85B9A6D"},"cell_type":"code","source":"//package org.lipn.som.utils\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.rdd.RDD\n\n/**\n * Company : Altic - LIPN\n * User: Tugdual Sarazin\n * Date: 07/01/14\n * Time: 12:37\n */\nobject SparkReader {\n  def parse(sc: SparkContext, filePath: String, splitRegex: String): RDD[NamedVector] = {\n    sc.textFile(filePath).map{line =>\n      val arrayDouble = line.split(splitRegex).map(_.toDouble)\n      new NamedVector(arrayDouble.dropRight(1), arrayDouble.last.toInt)\n    }\n  }\n}","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.SparkContext\nimport org.apache.spark.rdd.RDD\ndefined object SparkReader\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":8,"time":"Took: 1 second 288 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"F39D6EFB33AF498D8AE47212D8D7CB83"},"cell_type":"code","source":":markdown\nSparkReader.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res12: String = SparkReader.scala\n"},{"metadata":{},"data":{"text/markdown":"SparkReader.scala"},"output_type":"execute_result","execution_count":9,"time":"Took: 1 second 662 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"B29DB159843A4CA685233DC832AB8E1B"},"cell_type":"code","source":":markdown\n#NmiMetric.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res14: String = #NmiMetric.scala\n"},{"metadata":{},"data":{"text/markdown":"#NmiMetric.scala"},"output_type":"execute_result","execution_count":10,"time":"Took: 1 second 563 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"B5027B8CE462421B85E62425AC56ADC8"},"cell_type":"code","source":"//package org.lipn.som.utils\n\n/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 24/05/13\n * Time: 19:02\n * To change this template use File | Settings | File Templates.\n */\n//object NmiMetric extends App {\nobject NmiMetric {\n  def jointProbabilty(x: Array[Int], y: Array[Int]) {\n\n  }\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"defined object NmiMetric\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":11,"time":"Took: 1 second 102 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"EC59E17DA3FD4582857637194E20BFBE"},"cell_type":"code","source":":markdown\n#AbstractPrototype.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res17: String = #AbstractPrototype.scala\n"},{"metadata":{},"data":{"text/markdown":"#AbstractPrototype.scala"},"output_type":"execute_result","execution_count":12,"time":"Took: 1 second 445 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"74AF2500F11D4470B975946BAAEE9254"},"cell_type":"code","source":"//package org.lipn.som.global\nimport org.apache.spark.mllib.linalg.{Vectors, Vector, DenseVector}\n\n//import org.apache.spark.util\n\n/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 14/06/13\n * Time: 12:42\n * To change this template use File | Settings | File Templates.\n */\nabstract class AbstractPrototype(val id: Int, var _point: DenseVector) extends Serializable {\n  def update(newPoint: DenseVector): Double = {\n //   val dist = _point.dist(newPoint)\n  val dist = Vectors.sqdist(_point, newPoint)\n\n    _point = newPoint\n    dist\n  }\n\n // def dist(data: Vector) = _point.dist(data) // a modifier: - ajouter une pondÃ©ration fixe; - ajouter une pondÃ©ration adaptative\ndef dist(data: DenseVector) = Vectors.sqdist(_point,data) // a modifier: - ajouter une pondÃ©ration fixe; - ajouter une pondÃ©ration adaptative\n\n//def dist(prototype: AbstractPrototype) = _point.dist(prototype._point)\ndef dist(prototype: AbstractPrototype) = Vectors.sqdist(_point,prototype._point)\n  \n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.linalg.{Vectors, Vector, DenseVector}\ndefined class AbstractPrototype\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":13,"time":"Took: 815 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"0BD5BA82938F41DD8C42AECAD28ED107"},"cell_type":"code","source":":markdown \n#AbstractModel.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res20: String = #AbstractModel.scala\n"},{"metadata":{},"data":{"text/markdown":"#AbstractModel.scala"},"output_type":"execute_result","execution_count":14,"time":"Took: 1 second 425 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"D5C2612F7811426C94AD8C33103A6B51"},"cell_type":"code","source":"import org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.linalg.DenseVector\n\n//import org.apache.spark.ml.linalg.{Vector,Vectors}\n/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 14/06/13\n * Time: 12:34\n * To change this template use File | Settings | File Templates.\n */\n\n class pointObj(\n    val data: DenseVector,//the numeric part of the data-point\n    //val label: Int,            //the real (provided) label\n    val id: Int               //the identifier(=numeroLigne) of the data-point\n    ) extends Serializable {\n  override def toString: String = {\" \"\n    //data.toArray.deep.mkString(\", \") + pointPartBin.toArray.deep.mkString(\", \")\n    /*\"partieNumerique -> \"+pointPartNum.toArray.deep.mkString(\"[\", \", \", \"]\") +\n    \"; partieBinaire -> \"+pointPartBin.toArray.deep.mkString(\"[\", \", \", \"]\")*/ \n  } \n }\n \n\nabstract class AbstractModel(val prototypes: Array[AbstractPrototype]) extends Serializable {\n  def size = prototypes.size\n\n  def findClosestPrototype(data: DenseVector): AbstractPrototype = {\n    prototypes.minBy(proto => proto.dist(data))\n  }\n  \n  def findClosestPrototypeId(data: DenseVector): AbstractPrototype = {\n    prototypes.minBy(proto => proto.dist(data))\n  }  \n\n  def apply(i: Int) = prototypes(i)\n\n  def assign(dataset: RDD[pointObj]): RDD[(Int, Int)] =  {\n    dataset.map(d => (this.findClosestPrototype(d.data).id, d.id))\n  }\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.linalg.DenseVector\ndefined class pointObj\ndefined class AbstractModel\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":15,"time":"Took: 1 second 65 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"F5437D9C9BB94F9CA5F35AAF31ACC465"},"cell_type":"code","source":":markdown\n#WriterCluster.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res23: String = #WriterCluster.scala\n"},{"metadata":{},"data":{"text/markdown":"#WriterCluster.scala"},"output_type":"execute_result","execution_count":16,"time":"Took: 1 second 453 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"B373C55A978C48938C66A7E045AF1AB3"},"cell_type":"code","source":"//package org.lipn.som.utils\nimport org.apache.spark.mllib.linalg.DenseVector\nimport java.io._\nimport org.apache.spark.rdd.RDD\n//import org.lipn.som.global.AbstractModel\n\n\nobject WriterClusters {\n  def js(data: RDD[NamedVector], model: AbstractModel, path: String) = {\n    val writer = new PrintWriter(new File(path))\n\n    val dataArray = data.collect\n    var str = \"var dataset = [\"\n\n    dataArray.foreach {d =>\n      val closestNeuron = model.findClosestPrototype(d)\n      if (d != dataArray.head) str += ','\n      str += d.toJSON(closestNeuron.id)\n    }\n\n    /*model.foreach{proto =>\n      str += ','\n      str += \"{\"\n      for (i <- 0 until proto._point.length) {\n        str += \"attr\"+i+\":\"+proto._point(i)+\", \"\n      }\n      str += \"cls:\\\"proto\\\", \"\n      str += \"clusterId:-\"+proto.id\n      str += \"}\\n\"\n    }\n    */\n    str += \"];\"\n    writer.write(str)\n\n    writer.close()\n  }\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.linalg.DenseVector\nimport java.io._\nimport org.apache.spark.rdd.RDD\ndefined object WriterClusters\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":17,"time":"Took: 1 second 142 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"3F31F7F976564E849122CA88BA83B218"},"cell_type":"code","source":":markdown \n#AbstractTrainer.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res26: String = #AbstractTrainer.scala\n"},{"metadata":{},"data":{"text/markdown":"#AbstractTrainer.scala"},"output_type":"execute_result","execution_count":18,"time":"Took: 1 second 407 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"0533032DC3BF449796B196D35705E2ED"},"cell_type":"code","source":"/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 14/06/13\n * Time: 12:31\n * To change this template use File | Settings | File Templates.\n */\n\nimport org.apache.spark.mllib.linalg.DenseVector\nimport java.util.concurrent.TimeUnit._\nimport org.apache.spark.rdd.RDD\nimport scala.concurrent.duration.{FiniteDuration, Duration}\n//import org.apache.spark.ml.linalg.{Vector,Vectors}\n\ntrait AbstractTrainer extends Serializable {\n  private var _it = 0\n  def getLastIt = _it\n\n  private var _converge = 1.0\n  def getLastConvergence = _converge\n\n  private var _trainingDuration = Duration.Zero\n  def getLastTrainingDuration = _trainingDuration\n\n  protected def initModel(dataset: RDD[DenseVector], modelOptions: Map[String, String])\n\n  protected def trainingIteration(dataset: RDD[DenseVector], currentIteration: Int, maxIteration: Int): Double\n\n  protected def getModel: AbstractModel\n\n  final def training(dataset: RDD[DenseVector],\n                     modelOptions: Map[String, String] = Map.empty,\n                     maxIteration: Int = 100,\n                     endConvergeDistance: Double = 0.001): AbstractModel = {\n\n    val datasetSize = dataset.count()\n\n    val startLearningTime = System.currentTimeMillis()\n\n    val model = initModel(dataset, modelOptions)\n    _it = 0\n    _converge = 1.0\n\n    while (_converge > endConvergeDistance && _it < maxIteration) {\n\n      // Training iteration\n      val sumConvergence = trainingIteration(dataset, _it, maxIteration)\n\n      // process convergence\n      _converge = sumConvergence / datasetSize\n      _it += 1\n    }\n\n    _trainingDuration = Duration.create(System.currentTimeMillis() - startLearningTime, MILLISECONDS)\nprintln(\"le model apres training est : \"+getModel)\n\n    // return the model\n    getModel\n  }\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.linalg.DenseVector\nimport java.util.concurrent.TimeUnit._\nimport org.apache.spark.rdd.RDD\nimport scala.concurrent.duration.{FiniteDuration, Duration}\ndefined trait AbstractTrainer\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":19,"time":"Took: 1 second 97 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"4AC18190D25842648090D447EC6D777A"},"cell_type":"code","source":":markdown\n#SomTrainerA.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res29: String = #SomTrainerA.scala\n"},{"metadata":{},"data":{"text/markdown":"#SomTrainerA.scala"},"output_type":"execute_result","execution_count":20,"time":"Took: 1 second 442 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"6996406D601D42538560B9C882D6B797"},"cell_type":"code","source":"//package org.lipn.som.som\n\nimport scala.math.{abs, exp}\nimport java.util.Random\nimport org.apache.spark.rdd.RDD\n//import org.apache.spark.SparkContext._\n//import org.apache.spark.util.Vector\n//import org.lipn.som.global.{AbstractPrototype, AbstractModel, AbstractTrainer}\n//import org.lipn.som.utils.NamedVector\nimport scala.concurrent.duration.{FiniteDuration, Duration}\n//import org.apache.spark.ml.linalg.{Vector,Vectors}\nimport org.apache.spark.mllib.linalg.DenseVector\n\n/**\n * User: tug\n * Date: 14/06/13\n * Time: 12:35\n */\nclass SomTrainerA extends AbstractTrainer {\n  val DEFAULT_SOM_ROW = 10\n  val DEFAULT_SOM_COL = 10\n  val DEFAULT_TMAX = 8\n  val DEFAULT_TMIN = 1\n  val DEFAULT_INITMAP = 0\n  val DEFAULT_INITMAPFile = \"\"\n  val DEFAULT_SEPARATOR = \"\"\n  val SIZE_REAL_VARS = 10\n  \n  var tmax: Double = DEFAULT_TMAX\n  var tmin: Double = DEFAULT_TMIN\n  var initMap: Int = DEFAULT_INITMAP\n  var initMapFile: String = DEFAULT_INITMAPFile\n  var sep = DEFAULT_SEPARATOR\n  var sizeRealVars: Int = SIZE_REAL_VARS\n \n\n  protected var _somModel: SomModel = null\n  protected def getModel: AbstractModel = _somModel\n\n  protected def initModel(dataset: RDD[DenseVector], modelOptions: Map[String, String]) {\n    var nbRow = DEFAULT_SOM_ROW\n    var nbCol = DEFAULT_SOM_COL\n    if (modelOptions != null) {\n      nbRow = modelOptions(\"clustering.som.nbrow\").toInt\n      nbCol = modelOptions(\"clustering.som.nbcol\").toInt\n      tmax = modelOptions.get(\"clustering.som.tmax\").map(_.toDouble).getOrElse(DEFAULT_TMAX)\n      tmin = modelOptions.get(\"clustering.som.tmin\").map(_.toDouble).getOrElse(DEFAULT_TMIN)\n      initMap = modelOptions.get(\"clustering.som.initMap\").map(_.toInt).getOrElse(DEFAULT_INITMAP)\n      initMapFile = modelOptions.get(\"clustering.som.initMapFile\").map(_.toString).getOrElse(DEFAULT_INITMAPFile)\n      sep = modelOptions.get(\"clustering.som.separator\").map(_.toString).getOrElse(DEFAULT_SEPARATOR)\n      sizeRealVars = modelOptions.get(\"clustering.som.nbRealVars\").map(_.toInt).getOrElse(SIZE_REAL_VARS)\n    }\n\n    val mapSize = nbRow * nbCol\n    // todo : replace random = 42\n    var selectedDatas: Array[DenseVector] = Array()\n    if (initMap == 0) {    \n       selectedDatas = {\n      dataset.takeSample(withReplacement = false, mapSize, new Random().nextInt())\n    }\n    } else {\n       selectedDatas = {\n        scala.io.Source.fromFile(initMapFile).getLines().toArray.map(x => new DenseVector(x.split(sep).map(_.toDouble)))\n      }\n    }\n\n    // todo : Check /nbCol et %nbCOl\n    val neuronMatrix = Array.tabulate(mapSize)(id => new SomNeuron(id, id/nbCol, id%nbCol, selectedDatas(id)))\n    _somModel = new SomModel(nbRow, nbCol, neuronMatrix)\n  }//init model\n\n  protected def trainingIteration(dataset: RDD[DenseVector], currentIteration: Int, maxIteration: Int): Double = {\n    \n    val T = processT(maxIteration, currentIteration)\n\n    // create som observations\n    val mapping = dataset.map{d =>\n      val bestNeuron = _somModel.findClosestPrototype(d).asInstanceOf[SomNeuron]\n      \n      //ML: à rentrer dans la condition\n      var mapBin: scala.collection.immutable.Vector[(Int, Int)] = scala.collection.immutable.Vector()\n      \n      //binary part\n      if (d.size > this.sizeRealVars){\n        val d2: scala.collection.immutable.Vector[Double] = d.toArray.drop(sizeRealVars).toVector.asInstanceOf[scala.collection.immutable.Vector[Double]]\n        mapBin = d2.map(x => if (x == 1) (1,0) else (0,1))\n      }\n\n\n      _somModel.prototypes.map{proto =>\n        val neuron = proto.asInstanceOf[SomNeuron]\n        val factor = neuron.factorDist(bestNeuron, T) // K(delta(.-.)/T)\n             \n        //binary part\n        var mapBinPondere: scala.collection.immutable.Vector[(Double, Double)] = scala.collection.immutable.Vector()\n       \n        //ML:ajouter la condition (d.length > this.sizeRealVars), sinon vecteur vide\n        if (mapBin.size > 0) {\n          mapBinPondere = mapBin.map(x => (x._1 * factor, x._2 * factor))\n        }\n        \n        //ML: dans le cas de non présence de réelle vecteur vide, pareil pour les varibales binaires\n        new SomObsA(new DenseVector(d.toArray.take(sizeRealVars).map(_ * factor)), factor, mapBinPondere, neuron.id)\n        // ligne originale\n        //new SomObsA(Vector(d.toArray.take(sizeRealVars)) * factor, factor, mapBinPondere, neuron.id)\n\n      }\n    } //end mapping\n\n    // Concat observations\n    val concatObs = mapping.reduce{(obs1, obs2) =>\n      for (i <- 0 until obs1.length) {\n        obs1(i) += obs2(i)\n      }\n      obs1\n    }\n\n    // Update model and process convergence distance\n    //val x: Array[Double] = concatObs.map(_somModel.update)\n    concatObs.map(_somModel.update).sum\n    \n  }//end trainingIteration\n\n  //protected def processT(maxIt:Int, currentIt:Int) = maxIt.toFloat - currentIt\n   protected def processT(maxIt:Int, currentIt:Int) =\n      this.tmax*math.pow(this.tmin/this.tmax,currentIt/(maxIt.toFloat-1))\n\n  protected class SomModel(val nbRow: Int, val nbCol: Int, neurons: Array[SomNeuron])\n    extends AbstractModel(neurons.asInstanceOf[Array[AbstractPrototype]]) {\n\n    // Update the data point of the neuron\n    // and return the distance between the new and the old point\n    def update(obs: SomObsA) = neurons(obs.neuronId).update(obs.compute)\n\n\n    override def toString: String = {\n      var str = \"\"\n      for(neuron <- neurons) {\n        str += neuron+\"\\n\"\n      }\n      str\n    }\n  }\n\n  protected class SomNeuron(id: Int, val row: Int, val col: Int, point: DenseVector) extends AbstractPrototype(id, point) {\n    def factorDist(neuron: SomNeuron, T: Double): Double = {\n      exp(-(abs(neuron.row - row) + abs(neuron.col - col)) / T)\n    }\n\n    override def toString: String = {\n      \"(\"+row+\", \"+col+\") -> \"+point\n    }\n  }\n\n  protected class SomObsA(var numerator:DenseVector, var denominator: Double, var mapBinPonderation: scala.collection.immutable.Vector[(Double, Double)], val neuronId: Int) extends Serializable {\n    def +(obs: SomObsA): SomObsA = {\n      //ML:que lorsqu'on a des données réelles\n      numerator = new DenseVector( obs.numerator.toArray.zip(numerator.toArray).map( x => x._1 + x._2 ) )\n      denominator += obs.denominator\n      \n\n      // calcul de la somme des pondÃ©ration des 1 et des 0\n     //ML:ajouter la condition (d.length > this.sizeRealVars)\n      \n      var mapBinPonderation2: scala.collection.immutable.Vector[(Double, Double)] = scala.collection.immutable.Vector()\n    if (mapBinPonderation.size>0)\n      {\n      for (i <-0 until mapBinPonderation.size){\n        val c1: Double = mapBinPonderation(i)._1 + obs.mapBinPonderation(i)._1\n        val c0: Double = mapBinPonderation(i)._2 + obs.mapBinPonderation(i)._2\n         mapBinPonderation2==mapBinPonderation2 :+ (c1, c0)\n      }\n      mapBinPonderation = mapBinPonderation2\n    }\n      \n      this\n    }\n\n    //def compute = numerator / denominator\n    def compute = {\n      // Linge originale\n      //val newPointsReal = numerator / denominator\n      val newPointsReal = new DenseVector( numerator.toArray.map(_ / denominator) )\n      \n      // calcul de la mediane\n      //ML:ajouter la condition (d.length > this.sizeRealVars)\n      //var newPointsBin:Array[Double]=Array()\n      \n      var newPointsBin: scala.collection.immutable.Vector[Double] = scala.collection.immutable.Vector()\n      \n      if (mapBinPonderation.size>0)\n      {\n        newPointsBin = mapBinPonderation.map {e =>\n        if (e._1 >= e._2) 1.0 else 0.0}\n      }\n     \n      // concatenation de la partie real et binaire\n      new DenseVector(newPointsReal.toArray ++ newPointsBin) \n       \n    }\n\n    override def toString = numerator.toString()+\" : \"+denominator.toString\n  }//end SomObsA\n\n\n\n  def purity(dataset: RDD[NamedVector]): Double = {\n    //val nbRealClass = dataset.map(_.cls).reduce(case(cls1,cls2))\n\n    val sumAffectedDatas = dataset.map(d => ((_somModel.findClosestPrototype(d).id, d.cls), 1))\n      .reduceByKey{case (sum1, sum2) => sum1+sum2}\n\n    val maxByCluster = sumAffectedDatas.map(sa => (sa._1._1, sa._2))\n      .reduceByKey{case (sum1, sum2) => sum1.max(sum2) }\n      .map(_._2)\n      .collect()\n\n    maxByCluster.sum / dataset.count().toDouble\n  }\n\n  def affectations(dataset: RDD[NamedVector]): RDD[(Int, Int)] = {\n    dataset.map(d => (d.cls, _somModel.findClosestPrototype(d).id))\n  }\n} //end SomTrainerA\n\n class pointObj(\n    val data: DenseVector,//the numeric part of the data-point\n    //val label: Int,            //the real (provided) label\n    val id: Int               //the identifier(=numeroLigne) of the data-point\n    ) extends Serializable {\n  override def toString: String = {\" \"\n    //data.toArray.deep.mkString(\", \") + pointPartBin.toArray.deep.mkString(\", \")\n    /*\"partieNumerique -> \"+pointPartNum.toArray.deep.mkString(\"[\", \", \", \"]\") +\n    \"; partieBinaire -> \"+pointPartBin.toArray.deep.mkString(\"[\", \", \", \"]\")*/ \n  } \n }\n \n","outputs":[{"name":"stdout","output_type":"stream","text":"import scala.math.{abs, exp}\nimport java.util.Random\nimport org.apache.spark.rdd.RDD\nimport scala.concurrent.duration.{FiniteDuration, Duration}\nimport org.apache.spark.mllib.linalg.DenseVector\ndefined class SomTrainerA\ndefined class pointObj\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":21,"time":"Took: 2 seconds 11 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"DD16EAC03BA54D9C80AD4C60D31DD65A"},"cell_type":"code","source":":markdown\n#RunSom.scala","outputs":[{"name":"stdout","output_type":"stream","text":"res32: String = #RunSom.scala\n"},{"metadata":{},"data":{"text/markdown":"#RunSom.scala"},"output_type":"execute_result","execution_count":22,"time":"Took: 1 second 469 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"951756FD367C44808BEBE637EA7EC99C"},"cell_type":"code","source":"//package org.lipn.som.som\n\n/*import org.lipn.som.global.AbstractModel\nimport org.lipn.som.global.AbstractModel\nimport org.lipn.som.global.AbstractPrototype\nimport org.lipn.som.global.AbstractTrainer\nimport org.lipn.som.utils.NamedVector\nimport org.lipn.som.utils.DataGenerator\n*/\n\n\nobject RunSom{\n  \n    def main(args:Array[String]) {\n      run(\n          sparkMaster = args(0),\n          intputFile = args(1),\n          outputDir = args(2),\n          execName = args(3),\n          nbRow = args(4).toInt,\n          nbCol = args(5).toInt,\n          tmin = args(6).toDouble,\n          tmax = args(7).toDouble,\n          convergeDist = args(8).toDouble,\n          maxIter = args(9).toInt,\n          sep = args(10),\n          initMap = args(11).toInt, //0: initialisation aleatoire\n          initMapFile = args(12)\n      )  \n    }\n  \n  def run(\n    sparkMaster: String,\n    intputFile: String,\n    outputDir: String,\n    execName: String = \"RunSom\",\n    nbRow: Int = 10, \n    nbCol: Int = 10, \n    tmin: Double = 0.9, \n    tmax: Double = 8,\n    convergeDist: Double = -0.001,\n\t\tmaxIter: Int = 50,\n\t\tsep : String = \";\",\n\t\tinitMap: Int = 0,\n\t\tinitMapFile : String = \"\",\n\t\tnbRealVars : Int = 10\n    ) = {\n    val sparkConf = new SparkConf().setAppName(execName)\n\t\tsparkConf.setMaster(sparkMaster)\n\t\tval sc = new SparkContext(sparkConf)\n\n    val somOptions = Map(\n    \t\t\"clustering.som.nbrow\" -> nbRow.toString, \n    \t\t\"clustering.som.nbcol\" -> nbCol.toString,\n    \t\t\"clustering.som.tmin\" -> tmin.toString,\n    \t\t\"clustering.som.tmax\" -> tmax.toString,\n    \t\t\"clustering.som.initMap\" -> initMap.toString,\n    \t\t\"clustering.som.initMapFile\" -> initMapFile.toString,   \n    \t\t\"clustering.som.separator\" -> sep.toString,\n        \"clustering.som.nbRealVars\" -> nbRealVars.toString\n    \t\t)\n\t    \t\n\t  val trainingDatasetId = sc.textFile(intputFile).map(x => new DenseVector(x.split(sep).map(_.toDouble))).cache() \n\t  \n\t  val trainingDataset = trainingDatasetId.map{ e =>\n\t     new DenseVector(e.toArray.take(e.size - 1)) \n\t  }.cache()\n\t    \n \n\t  println(s\"nbRow: ${trainingDataset.count()}\")\n\t    \t\t\n\t\tval model = trainingAndPrint(new SomTrainerA, trainingDataset, somOptions, maxIter, convergeDist)\n\t\tprint(\"le model est : \"+model)\n\t\tsc.parallelize(model.prototypes).saveAsTextFile(outputDir+\"/model\")\n\t    \t\n\t\t\n\t  // transformer un point de donnÃ©es en un objet contenant la donnÃ©es et son identifiant \n\t  val trainingDatasetObj = trainingDatasetId.map{ e =>\n\t    val dataPart = e.toArray.take(e.size - 1) // the last column represents the identifier\n\t    val id = e.toArray(e.size - 1).toInt\n\t    new pointObj(new DenseVector(dataPart), id)\n\t  }.cache()\n\t  \n\t  trainingDataset.unpersist(true) \n\t  \n\t\t//model.assign(trainingDatasetObj).saveAsTextFile(outputDir+\"/assignDatas\")\n\t\t\n//\t\tsc.stop()\n  }\n\n\n\tdef purity(model: AbstractModel, dataset: RDD[NamedVector]): Double = {\n\t\t\t//val nbRealClass = dataset.map(_.cls).reduce(case(cls1,cls2))\n\n\t\t\tval sumAffectedDatas = dataset.map(d => ((model.findClosestPrototype(d).id, d.cls), 1))\n\t\t\t\t\t.reduceByKey{case (sum1, sum2) => sum1+sum2}\n\n\t\t\tval maxByCluster = sumAffectedDatas.map(sa => (sa._1._1, sa._2))\n\t\t\t\t\t.reduceByKey{case (sum1, sum2) => sum1.max(sum2) }\n\t\t\t.map(_._2)\n\t\t\t.collect()\n\n\t\t\tmaxByCluster.sum / dataset.count().toDouble\n\t}\n\n\tdef trainingAndPrint(trainer: AbstractTrainer,\n\t\t\tdataset: RDD[DenseVector],\n\t\t\tmodelOptions: Map[String, String],\n\t\t\tmaxIteration: Int = 100,\n\t\t\tendConvergeDistance: Double): AbstractModel = {\n\t\t\tval model = trainer.training(dataset, modelOptions, maxIteration, endConvergeDistance)\n\t\t  // Initi  alisation du model\n\t\t\t//val trainer = new SomTrainer(nbRow, nbCol, trainingDataset, convergeDist, maxIter)\n\t\t\t//val model = trainer.model\n\n  \t\tprintln(\"-- Convergence Distance : \" + trainer.getLastConvergence)\n  \t\tprintln(\"-- NbIteration : \" + trainer.getLastIt)\n  \t\tprintln(\"-- Training duration : \" + trainer.getLastTrainingDuration)\n  \t\tprintln(\"-- The model : \" + model)\n  \t\t\n  \t\t\n  \t\tmodel\n\t}\n}\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"defined object RunSom\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":23,"time":"Took: 1 second 620 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"id":"0D9943E8FC48402083C7B5541F4AFD3A"},"cell_type":"markdown","source":"#DataGen"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"C7147CCF43F941E787B71C1AD888EF40"},"cell_type":"code","source":"//package org.lipn.som.utils\nimport org.apache.spark.mllib.linalg.DenseVector\n\n//import util.Random\n//import org.apache.spark.util.Vector\n//import org.apache.spark.SparkContext\nimport org.apache.spark.rdd.RDD\nimport scala.Array\n\n\n/**\n * Created with IntelliJ IDEA.\n * User: tug\n * Date: 27/03/13\n * Time: 17:07\n * To change this template use File | Settings | File Templates.\n */\nobject DataGen extends Serializable {\n\n  class Center(val cls: Int, val rayon: Double, val elements: Array[Double]) extends Serializable {\n    def this(cls: Int, dims: Int, a: Double, b: Double, rayon: Double) = this(cls, rayon, Array.fill(dims)(new Random(42).nextGaussian() * a + b))\n  }\n\n\n  def generate(sc: SparkContext,\n                        numPoints: Int,\n                        nbCls: Int,\n                        d: Int,\n                        numPartitions: Int = 2): RDD[NamedVector] =\n  {\n    // First, generate some centers\n    val rand = new Random(42)\n    val r = 1.0\n    val centers = Array.fill(nbCls)(Array.fill(d)(rand.nextGaussian() * r))\n    // Then generate points around each center\n    sc.parallelize(0 until numPoints, numPartitions).map{ idx =>\n      val cls = idx % nbCls\n      val center = centers(cls)\n      val rand2 = new Random(42 + idx)\n      new NamedVector(Array.tabulate(d)(i => center(i) + rand2.nextGaussian()), cls)\n    }\n  }\n}\n\nobject DataGenerator extends Serializable {\n  private val rand = new Random\n\n  private case class DModel(A: Double, B: Double) {\n    def gen =  A * rand.nextDouble() + B\n  }\n\n  private case class PModel(cls: Int, dmodels: Array[DModel]) {\n    def genVector = new DenseVector(dmodels.map(_.gen))\n    def genNamedVector = new NamedVector(dmodels.map(_.gen), cls)\n  }\n\n  private def PModel2D(cls: Int, A: Double, B: Double, C: Double) = PModel(cls, Array(DModel(A, B), DModel(A, C)))\n\n  private def PModelND(cls: Int, dims: Int, A: Double, B: Double) = PModel(cls, Array.fill(dims)(DModel(A, B)))\n\n  class SModel(N: Int, pmodels: Array[PModel]) {\n    private def nextVector(i: Int) = pmodels(rand.nextInt(pmodels.size)).genVector\n    private def nextNamedVector(i: Int) = pmodels(rand.nextInt(pmodels.size)).genNamedVector\n    def getVector = Array.tabulate(N)(nextVector)\n    def getNamedVector = Array.tabulate(N)(nextNamedVector)\n  }\n  val CLS_1 = 1\n  val CLS_2 = 2\n  val CLS_3 = 3\n  val CLS_4 = 4\n\n  def genH2Dims(N: Int) = new SModel(N, Array(\n    PModel2D(CLS_1, 1, 1, 1),\n    PModel2D(CLS_1, 1, 1, 2),\n    PModel2D(CLS_1, 1, 1, 3),\n    PModel2D(CLS_1, 1, 2, 2),\n    PModel2D(CLS_1, 1, 3, 1),\n    PModel2D(CLS_1, 1, 3, 2),\n    PModel2D(CLS_1, 1, 3, 3)\n  ))\n\n  def gen2Cls2Dims(N: Int) = new SModel(N, Array(\n    PModel2D(CLS_1, 1, 1, 1),\n    PModel2D(CLS_2, 2, 2, 2)\n  ))\n\n  def gen2ClsNDims(N: Int, dims: Int) = new SModel(N, Array(\n    PModelND(CLS_1, dims, 1, 1),\n    PModelND(CLS_2, dims, 2, 2)\n  ))\n}\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.linalg.DenseVector\nimport org.apache.spark.rdd.RDD\nimport scala.Array\ndefined object DataGen\ndefined object DataGenerator\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":24,"time":"Took: 1 second 778 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"E73522D116E34C998FBAFC211BD34F1B"},"cell_type":"code","source":":markdown\n# main with generated data","outputs":[{"name":"stdout","output_type":"stream","text":"res43: String = # main with generqted data\n"},{"metadata":{},"data":{"text/markdown":"# main with generqted data"},"output_type":"execute_result","execution_count":30,"time":"Took: 1 second 488 milliseconds, at 2017-6-14 11:16"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"4169DCF0BBD34B898E5D688BDE5D8774"},"cell_type":"code","source":" import scala.math.max\n  val nbRowSOM = 10\n  val nbColSOM = 10\n  val nbIter = 30\n  val dataNbObs = 2000\n  val dataNbVars = 10\n  val dataNbCls = 2 //classes\n  val datas = DataGen.generate(sc, dataNbObs, dataNbCls, dataNbVars, max(dataNbObs/10000, 1))\n  datas.cache()\n  datas.count()\n  var startLearningTime = System.currentTimeMillis()\n\n println(\"****************\\n***** SOM  *****\\n****************\")\n  val som = new SomTrainerA\n  val somOptions = Map(\"clustering.som.nbrow\" -> nbRowSOM.toString, \"clustering.som.nbcol\" -> nbColSOM.toString)\n  val somConvergeDist = -0.1\n  startLearningTime = System.currentTimeMillis()\n  val model = som.training(datas.asInstanceOf[RDD[DenseVector]], somOptions, nbIter, somConvergeDist)\n  val somDuration = Duration(System.currentTimeMillis() - startLearningTime, MILLISECONDS)\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"****************\n***** SOM  *****\n****************\nle model apres training est : (0, 0) -> #1 [1.390677705912189,1.3740585164389065,0.6265104422009801,-0.7391539010366508,-1.0966525190993068,-2.1163540525925586,-1.100816338437808,-0.0648554675531714,-2.3660711385780155,1.8096766358427605]\n(0, 1) -> #0 [2.916317248527624,1.4850935399237892,0.1026936828599081,-0.5974828211251034,-2.1892781897398645,0.9903256158547233,-2.604882481794661,-1.3346408551953783,-1.436678768509722,0.3485573020722432]\n(0, 2) -> #0 [2.231973533972981,1.952858412123533,-0.2294413782668594,-0.815222267043838,0.35051925133230727,2.1131392395986097,0.7618480161423095,-3.5552085133630724,-0.1291298765632156,2.8102367573736236]\n(0, 3) -> #1 [2.488175913050271,0.4396105446583758,1.062749500580943,0.025241194123188704,-0.4466746543962994,1.6504731196036821,-0.6432430750761047,-0.8812433352000026,-0.5769998113861416,-0.8846368798244151]\n(0, 4) -> #0 [1.8178650511252736,0.14562865031428096,-0.3108551984490585,-2.438243620692342,0.05214250374331153,0.6807791787242852,-1.1201644725450608,-0.42939002224408673,-0.2961427569996486,2.078875856922477]\n(0, 5) -> #0 [1.453047257945754,2.0982404973496513,-1.3172797926009727,-2.855332202999122,0.9232185852821071,-0.2882193234298084,-1.4113151582809507,-3.099549316221694,-0.32644874139587,1.1064694238716035]\n(0, 6) -> #0 [2.2348148889811617,2.2898543411883954,-1.913259560349492,0.5852248526070707,0.27144389130429636,0.4428391629438919,-1.4740930449194096,-1.1994056089514857,-0.2957084053302238,2.267737373191765]\n(0, 7) -> #1 [1.219144969844649,-1.1673442845276534,1.5162971659708295,0.05430563580864323,-0.17891205894274909,-0.09860531508530834,-1.1464227626673957,0.9531330017808695,-0.05039127714924718,0.22402990537253278]\n(0, 8) -> #0 [1.7813276586957414,0.1281199794450063,-0.9540068012424512,0.06810168934021776,0.18438429493635067,1.8383927653514878,-1.207653261506675,-0.994203817994471,-0.7471173406355169,1.465723904545292]\n(0, 9) -> #0 [1.5268782125313578,0.17605534756246977,-1.2808514234453732,-2.6473232534436866,1.1956527641748682,2.6317055304322263,-0.5657433651661146,-0.8031042956491382,0.3582481815887043,0.6600974763853876]\n(1, 0) -> #0 [3.1327622458320397,1.1893091456409848,-1.322935917403479,-1.4304645070594966,2.439606535680216,0.7169659763272107,-0.7188349247571542,0.4710497420128883,-1.0549522689439332,1.7020229883702418]\n(1, 1) -> #1 [1.482578138223591,0.6627813350491801,1.2520628224461205,-0.6867060747143461,-1.7121723938036588,1.0496325440308363,-0.6470377890157243,-0.4915644242258359,-2.168762070977353,0.7903867593621803]\n(1, 2) -> #0 [2.294381778350512,2.7391147782730743,-1.0480968040381389,-2.6857350008072145,-0.12457354242687352,-0.08780545134593043,-0.6911724554805982,-2.3068316982873696,-1.9410817261901505,1.5794227127230331]\n(1, 3) -> #0 [1.6222197274123096,0.1025698047818504,-2.079515943554668,-2.2977398664362845,-0.8112148144100417,2.041495945834492,-0.6693456656600658,1.0137852992774903,-1.1143571584929721,1.872947389877104]\n(1, 4) -> #1 [1.0161406554891785,-0.8787565072810246,-0.478524122971699,-1.02762391139197,-0.2247496806928868,0.653243751803503,0.0885931794384166,2.0470397685630086,-0.9597693842995756,-0.08768770109778956]\n(1, 5) -> #1 [1.3104368962461075,2.1083605043917863,1.0610114528747383,-2.3086784793976416,-1.441281537220647,-0.16459000056963674,0.3795397101141884,0.4345237389837394,-4.7684194666314905,0.005413107126064409]\n(1, 6) -> #0 [1.3125146504164336,0.3556142404425763,-0.7442195113278294,-0.6255254526248598,-0.19029659116441217,1.7112997166256563,-1.4045075610927618,0.4216599895736328,-1.3645523619815076,-0.3775393143900003]\n(1, 7) -> #0 [1.4303069751492852,0.0685299811635286,0.03128262345537414,-2.4659970347996225,-0.47915355351437167,2.5176799726805537,-1.9269536798508207,-3.176222982105518,0.09102360757297628,2.1709655850672656]\n(1, 8) -> #1 [1.094129457407381,1.044386423561751,0.19638128513785102,-1.3934571285083994,-2.8074063969057645,1.8358565824978434,-0.8447804347018169,0.9182231329343011,-0.4184913677119897,-0.9294553123217033]\n(1, 9) -> #1 [2.8042760228782813,-0.9023301811978564,0.8532875899159168,-1.2788842848886264,-0.5864817000114483,1.7652819971475688,-0.9950446536744119,0.4562954804574305,-0.7249991836870586,1.6189157675143218]\n(2, 0) -> #0 [2.7758100134547776,0.1893835593537957,-1.2993411389455833,-1.1718123293048737,0.862278992339953,0.6514987777985175,-0.15342754216342425,0.10696337835093295,1.6017508619617122,1.723388248590442]\n(2, 1) -> #1 [1.9536449576575843,0.0037029481320798446,2.987946032281483,-0.5157616229318526,-2.7456011222745467,0.7980352245707306,-2.179059353930088,1.3076513660774811,-2.5395036031242673,1.4937123439737732]\n(2, 2) -> #0 [2.9339404755780887,1.0547845854622326,-2.1507780970161856,0.4655852072388522,0.8552595767375128,0.9116944906747931,-3.1278213245081097,-0.35734675338016,-1.8770733453494652,0.7595453559912131]\n(2, 3) -> #1 [1.6433146181462273,-1.0993321433280598,1.4503470137641168,-0.8820791640348381,-2.2399059339267264,0.17884163180568816,-2.0661812738068193,0.908924551036759,-2.6175669550092917,1.2765370681155146]\n(2, 4) -> #0 [2.775213198869496,-0.2892792165579744,-0.8263693510159206,-2.4540464321286097,-0.20668762915604705,2.076009875188438,-1.086497047507553,-0.7481205807088117,-0.09042720712833041,2.6333410297557895]\n(2, 5) -> #0 [3.2731816909936082,0.9516895117157923,-0.016797324354105303,-1.2917307502355653,0.7302127899749398,-0.7660739428085395,-1.5923493809942748,-1.138751585308198,-1.4169794541276266,2.7339279422123868]\n(2, 6) -> #0 [1.4466475687491704,-0.16193445186344768,-2.302924286285437,-0.37991418889995265,-0.3085810955030254,-0.1885275409560786,-1.5270896119001112,-1.0442770609081045,-0.5349673730478722,1.7638450950835445]\n(2, 7) -> #1 [2.669563849962513,0.4432150274758825,-0.43556263587819766,-1.5127514517574205,-1.5692425727983748,0.9080667506653348,-1.0272492415446892,1.5154992035320798,-2.1223110352946595,1.034515624714869]\n(2, 8) -> #1 [3.1013132605002935,-1.2028526600970413,0.5291842385248591,-0.8424478570335436,-0.09729756518636634,-0.03715464948710584,-1.1066000766747845,0.7893570751701309,-1.8853665077353225,0.7157880885628909]\n(2, 9) -> #0 [1.8349676530264862,-0.44009508561571364,-2.829701720681374,-0.4713623485256162,1.0438194499301583,-0.013640673255768898,-0.03210586387254377,0.05532787860891042,-0.7085898041899718,0.6436991803416164]\n(3, 0) -> #1 [1.6913025459202895,-1.065522780569311,2.9918300282143426,-1.4154872800760012,-1.0001755824735827,-0.20274527353686328,-1.7115369872068285,1.5910617952117574,-2.348848123352054,-0.3347947505334888]\n(3, 1) -> #0 [2.9202942536190557,1.7907068487287319,0.7293768724123773,-0.43613772425754394,-0.982409589116507,1.0564126586099585,-0.9019634566286533,-1.6639371860674355,0.4073602006681376,3.083319805621975]\n(3, 2) -> #0 [1.5996605179928682,0.2651728082219049,-1.642819379091995,-0.8508833361948227,0.5434173872543183,1.0264767014421148,0.012714169873251135,-2.8367337475112375,0.6879864338238472,3.238489281067338]\n(3, 3) -> #1 [1.1772783905894804,0.5305836873610709,1.551858696207638,-1.2857224346249727,0.10605520726530959,1.4575946649347624,-1.1945092279806993,1.1642276785088108,-1.7666009369510518,0.8382011678119472]\n(3, 4) -> #1 [1.1720955554104076,-0.991070607448393,2.321336167913784,1.4484554488392496,-2.836056789030229,0.4302652679847067,-1.4736872063848128,0.8435015329620437,-3.6503892616730846,-0.1935465900893551]\n(3, 5) -> #1 [1.7882820334089846,1.3387594130915872,1.0446705083580154,-1.5189544108062418,-1.5592829075360148,2.4044720932654653,-0.5715304124124567,-0.8114787595904476,0.4213827837370876,0.8569900763675571]\n(3, 6) -> #1 [1.1806934596513488,0.9917419978414103,1.24917303703478,0.7136758120131932,-1.1851369045074978,-1.0800352054680116,1.0725776304338248,0.5215304502430264,-0.26539340147549595,0.6375364021937711]\n(3, 7) -> #1 [0.9132173707465386,-0.3423232801966437,2.00031613487625,-0.7962169514586102,-3.8538248364671124,-0.4342963982578137,0.6201210568145827,0.21185662116547987,-1.0215301277168678,2.42420916231833]\n(3, 8) -> #1 [2.198642077461564,1.6227667320720627,-1.2864195577699684,-0.8214612596334127,-1.0758739792943581,0.06403659542675605,-1.4401968283520639,0.2122299982819783,-0.9013696587111664,-0.3345613165703116]\n(3, 9) -> #1 [2.9675033008404377,-0.8931026639825927,2.3370985175240446,0.25739315713631217,-1.1882908885598364,0.4637060260164525,-0.8101795788280495,1.7045931667451732,-1.379931268287623,-0.35806230589054283]\n(4, 0) -> #1 [0.8972908893727299,0.24761734387311984,1.1299548909850154,-0.8268329208105197,-0.7971095723876165,2.146923409975956,-1.9329408456072317,2.911710619165211,-0.9734116983332763,1.7228250670203422]\n(4, 1) -> #0 [1.608703355632506,-0.164631584629518,-3.0552711382186617,-1.423353499887912,-0.7367772396380157,1.3568773068483932,-0.8899545469090919,-2.381130411294861,-1.275644552371588,2.32045954926561]\n(4, 2) -> #0 [1.1957350464863972,0.8298814181980607,-2.0408683161674217,-0.2773405563325524,-0.31680176985373826,-0.012721845530803466,-0.7371298759889335,-1.7235496815860742,-0.3771385614677239,1.2968310093706485]\n(4, 3) -> #0 [2.593225211455901,2.205088577036633,-2.0087453740224244,-0.8509240317201132,2.202835010353669,-0.062659729219818,-0.35774380879975304,-2.4729597171094735,-0.7343787225942701,1.4708392026346866]\n(4, 4) -> #0 [0.7707111752768647,0.6594083575969089,-3.4347071300729093,-1.800284972704203,1.3447553614527026,1.4718540020884259,-0.7494015259486274,-1.2529609815835703,-1.20275892604761,2.3334473175530492]\n(4, 5) -> #0 [2.106139641886846,1.728876062608684,0.8432866388433284,-1.7625136068298706,-0.32772541637093294,1.5207843062287019,-0.3988503171763276,-2.5861169369578296,0.01859103100822243,1.6178038618537336]\n(4, 6) -> #1 [2.659677052439535,0.11373952733879626,1.0802317662554026,-1.386227140246968,-1.13504254199846,0.14338711586431255,-1.5105441337374874,1.7199910465076214,-1.4445660692139648,1.6906421896707988]\n(4, 7) -> #0 [2.9552011870734303,-0.5363262887857557,0.7284893180691587,-1.7401391870666454,-0.7349946725680572,0.3491907882448834,-1.789888009447072,0.1886129588779848,0.09156686137089293,2.3150089287635525]\n(4, 8) -> #1 [2.2651258972503294,1.4279926031792962,2.2228769282286467,-1.1809588424409312,-2.146619892896087,1.2872019270060062,1.2070829451025096,-0.5910013973654977,-1.3011351947489171,-1.743028468107818]\n(4, 9) -> #1 [2.0028175331359703,0.2667846612351478,0.6779639393643611,-1.4248121619622536,-0.5401820893645667,0.5286815224551684,-0.3351569871417517,1.236820611345585,-1.6663131361858028,-1.0580939885785456]\n(5, 0) -> #0 [3.0159314993401125,1.5354257006662986,-0.7425679699468193,-1.0733650643901869,-0.599913601643518,0.8538035254710212,-0.9944839968323911,-2.6509850341547887,0.6315914179377368,1.583293425145445]\n(5, 1) -> #0 [1.5653501195581498,0.1651773456656016,0.17514150702717046,0.8447321891314494,-0.2560298121131191,0.38364706871288184,-1.5774005802434823,-1.129061950746258,-1.178502184059988,-0.24065654494746558]\n(5, 2) -> #0 [2.8592306067154225,-0.14462395191571698,0.9446831509450007,-0.26053428931006783,0.9195347028465148,0.5531961500858534,-0.7622204072070031,-0.7298456301844399,0.4084891831622256,1.231723681820342]\n(5, 3) -> #0 [2.3797000417328555,1.9716538846516496,-1.4589600004675933,-0.0284634600425282,0.06368436625609153,0.9915480259329298,0.5269233372389196,-2.250493268695532,0.4701367989522113,0.5939648566163273]\n(5, 4) -> #0 [1.3915443454339615,0.09916790720294832,0.1816887730457859,-0.6651133056737369,0.038657473738185344,-1.2441923231410754,-0.3969652605891453,-0.401729025143305,-0.7133068496829547,2.2170664816219903]\n(5, 5) -> #1 [1.4997368249701202,-1.4513328858724253,3.098171297543209,-1.5508495937098037,-0.5086102697990967,0.41843127907039623,-0.7192757347595675,-1.7968239953208223,-0.45823704481793226,0.029931426756761248]\n(5, 6) -> #0 [2.810779785525974,2.15513681259757,1.6497585152244458,-0.8468245612505074,-1.7496348062586442,2.3120646683873183,-2.329224482902253,-2.069507002962325,-0.38153568096731083,2.1331813712706658]\n(5, 7) -> #0 [2.1280476765155805,2.5574164128099897,0.7516601840168684,-0.985442213366495,1.7851518195934153,0.9073687321418468,-2.694915238565136,-1.9597573908573152,-0.617764171521026,1.804215541380275]\n(5, 8) -> #0 [1.6285745046833289,-0.3871807534750137,-0.6811005716422646,-1.8397301426556445,0.260464009718062,1.4386570675060737,-0.6189278759412795,-1.0467410457937376,0.4168001626759211,0.6907782525260434]\n(5, 9) -> #1 [1.1380474671888081,-0.6578900353120655,0.8686868028644644,-0.5932057607690013,-2.4276848975063867,-0.1835021128811541,0.11601421682503466,0.5872704354618216,-1.9011614889429502,-0.4846503647733707]\n(6, 0) -> #0 [3.337857785130257,1.7522521133339723,-1.0491399796370455,-3.313041502213455,0.40183479936356026,1.7263002856689535,-0.48023164130216345,-2.350607283943812,0.7087329517174662,1.9378376313715564]\n(6, 1) -> #0 [1.4148942160927804,0.2394370842243324,-0.5834887146398229,0.35791670766952066,-0.5001796475716092,0.1773189546514078,-1.7580484445748708,-2.0849281495941256,-1.3848211449288563,1.7027265958429467]\n(6, 2) -> #1 [2.626214220349222,-0.0992905800529561,1.6626677988837057,-1.5200244510790282,0.23810976780754034,0.8857034948223286,0.14285191279998588,-1.0817286196443716,-1.33556949974858,2.210559473145804]\n(6, 3) -> #0 [2.19058528674503,1.730596826444608,-1.2956300313055844,-0.8059215397010385,-1.2725638574677787,3.5152444167556807,-2.1516800698148706,-2.1018095992980674,-0.06985067863437136,1.4176387304304883]\n(6, 4) -> #1 [2.302386949355781,0.3535909440218418,0.7999546104478261,-1.7931585056672035,-1.5049037576999225,1.1335912814824445,-0.8518955273575164,-0.38372340876372457,-2.436472361610358,-0.14923936437086333]\n(6, 5) -> #0 [2.5794956310113113,-0.7996306940104595,-1.9281117628277462,-1.5605332262838387,-0.5426800763350774,2.1944474134178193,-0.5651308331075305,-0.9079468203498371,1.008085306971793,1.3076866032268064]\n(6, 6) -> #1 [2.264980690866971,0.5696101820797875,1.5353026547814144,-0.6802924294185542,-1.0173414941502292,0.12970279518724873,0.4778363690212677,-0.18515026794097178,-1.114075978938636,-1.4734753859101561]\n(6, 7) -> #0 [1.5930018639584753,1.8800079130614473,-2.7379456916297813,-0.32217096969794934,-1.3659757810559496,0.9785850393138118,-1.1783770906565638,0.7079013852201625,1.3301661859962894,-0.2729650916224946]\n(6, 8) -> #1 [1.590887818043437,-0.9979791708670821,2.7322007232359393,0.044605169354681506,-2.5247312921753364,1.090119753970386,-0.19797171803865182,0.30107361962330886,-4.1105530585488435,0.9624953825820837]\n(6, 9) -> #0 [1.8050505707012978,2.170089510702107,-0.9092927272578127,-2.235856034405369,0.6498558813229727,-0.6116358491280516,-1.3468822898613042,-3.0655508076855544,-0.2697160364683888,2.915031646839783]\n(7, 0) -> #1 [0.9210297705670859,0.3700197892882209,2.3992677798689233,-1.2541177851915013,-0.16286793702161528,-1.1200575395374237,-1.1846618504039963,-1.3058520747967026,-1.9600861413820523,1.5369784413857002]\n(7, 1) -> #1 [0.9352282391830793,-0.45386830381989596,0.6410201418112558,-1.5648427386632036,-0.9465100602097445,0.38527332985409773,0.593936869512298,-0.4285589468896873,0.5229818070020147,0.819577224413874]\n(7, 2) -> #1 [2.0118544042989024,-1.043676536406436,1.0318064932494533,-1.805965589855945,-0.9621932664490206,-1.1365364732610375,0.22803540681940582,0.6676858263009466,-2.325754963032706,0.599299476368264]\n(7, 3) -> #1 [0.9212760542639,-0.32205599594478673,2.7770338317605576,-1.3324713937457573,-1.6427791781027914,0.4743218216281497,-1.2484770948696893,0.3564961925188227,-0.7450220125684963,0.8076655484540227]\n(7, 4) -> #0 [1.8375821163164803,2.530715092822134,-0.5921438163077922,-1.376861119075438,0.08007671884977646,-0.1228679342881619,1.6303381267935166,-2.5892914382831487,-0.5048914052820979,1.8759930116242347]\n(7, 5) -> #1 [2.757864190111182,0.38049714169872584,2.2140634997944253,-1.588824171109107,-1.5403914638528078,0.5980976503942185,-0.21699078238601882,-1.4913961745364317,-1.152492247978407,0.07773568397827035]\n(7, 6) -> #1 [3.1751411954395143,-0.5623820540438957,1.072850674571973,1.0556899399969941,-1.1647986703265436,-2.437414329804525,0.5347539412266105,0.7161332919921184,-2.745563582741949,0.4808495450077622]\n(7, 7) -> #0 [2.6389509482884437,-0.14777195558138156,-0.17718936970801213,-2.410497643175698,-1.6380128974493913,1.5492690926960642,-0.6783136508892089,-0.1231308469045791,-0.7263118757875103,-0.5018131545005351]\n(7, 8) -> #0 [3.214154064089174,1.8224733770305197,-0.23139113463935013,0.3116913007053417,-0.5537220113952599,0.7097141313149674,-0.453877402507233,-1.751843932010433,-0.5828966143090083,0.9658394872960787]\n(7, 9) -> #0 [3.614193147169516,1.7379248410900567,-0.8627816223252777,-0.13331627598668905,0.1595564191945856,2.326811513003188,-1.2628054721262598,-1.681307805404269,0.15628334360724416,-0.031186712452923926]\n(8, 0) -> #1 [2.731626651705964,0.28058675134491984,1.779615246627654,-0.4366641441298032,-1.220099235079691,1.6887026499325524,-0.898244055992893,-2.0003896732144506,-2.017688882996371,-0.6435488801578348]\n(8, 1) -> #0 [2.9292815397268575,1.6811071859712996,-1.5737383742452584,-2.6801429818167644,-1.2760269213224575,1.6735630958968977,-2.8447322785410623,-1.1120958920272412,0.8804104859356143,0.2664292517642224]\n(8, 2) -> #1 [1.3231404150013684,-1.1848471258625604,2.28858279189938,-0.07432353654118662,-0.43832955446507926,0.589666482051882,-0.28096115890659423,1.9485063480162463,0.49031136055992985,-1.022942100873262]\n(8, 3) -> #1 [2.349708404790449,-0.4585098023686472,4.0097871038812265,-1.0363046325492493,-1.0555152827329017,1.1788441276413024,-0.3800823959953399,-0.04859091574420216,-1.887634374443829,0.04602253646171045]\n(8, 4) -> #0 [1.6435539224480116,-0.3332038168860748,-1.551246285245416,0.06869863672173149,1.6796738528469706,0.8297999245710299,-0.9736388167730683,-2.9281037208456615,0.9648530538749536,2.486434666470234]\n(8, 5) -> #0 [1.2277810379369825,1.2708296564143318,0.47599914261812426,-1.7799739463781237,-1.4542483876018397,-0.7410468495111053,-1.6063194381849986,-0.965829779590914,-0.6087915152224697,1.5219449229720572]\n(8, 6) -> #1 [1.5783077746320826,-1.803737954468199,0.9981820109574346,-0.9415843376914906,-1.450061784874298,2.8163197410283107,0.5213972818643855,-0.0014620045882547394,-1.3152059774913247,0.1416739955349552]\n(8, 7) -> #0 [3.0893648777512506,1.1052820906625929,-0.7632201414464173,-2.4952237953515346,2.0907564132197094,1.9899468426495661,-1.2805678357356873,-0.6464268337303724,1.1077184290928053,2.4828107486694053]\n(8, 8) -> #1 [0.8385723137152872,-0.30148263512673035,1.5850699366900232,-2.2227737525620817,-2.991656315014758,1.4753751662773409,-0.5782525888977842,-0.8511079651717011,-0.6912015571751945,0.6645791265600418]\n(8, 9) -> #1 [0.028840619109143595,0.4949791834238687,2.5156072468041306,-0.7807364031628758,-1.1993136900837653,0.21146295288602288,-1.3473937406366758,0.28909973252506066,-0.9855827866016948,1.7379172575715902]\n(9, 0) -> #1 [1.2620647267319653,1.3274589250252373,2.833125833928827,-0.8873944880421029,-1.5282506495636177,1.540139086251851,0.04632559962437255,0.7062859807046177,-0.8765244279994793,-0.05684995502180373]\n(9, 1) -> #1 [1.3607736725861113,0.873327215025212,1.9073105071046264,0.33896506500881507,0.7451868785003408,-1.289325216224834,-1.040344577549053,1.8873533514069072,-1.6020237687134904,0.2538276438495776]\n(9, 2) -> #0 [2.645722718662599,1.8942247308820563,-1.0750936813708738,-1.5826727688419813,-0.9135559277208496,-0.35571899221041425,-1.513878307081685,-1.5657205559597556,-0.15091487673719817,2.188724135224331]\n(9, 3) -> #0 [1.9706580037733215,-0.03278547628453632,-1.8555562096620462,-0.1277389412929052,1.41005875741243,2.021587706833168,0.07890232957621401,-1.5083943630732397,0.01964653768912894,1.9418762563719305]\n(9, 4) -> #0 [2.698457530793318,-0.037166887375637225,0.2921603440488738,-0.45275041725263077,0.5406185927331887,0.48487742421566715,-0.4227512966303252,-0.7987930342985265,0.28857210106907694,1.911518339563763]\n(9, 5) -> #1 [2.097125907152191,1.1226818744204834,0.8364120900242796,-0.6263298152027287,-0.8087728729509895,0.9880742452580269,-0.8386998870611981,0.9753077160707594,-0.8176170174942887,0.947472715286344]\n(9, 6) -> #0 [2.775945694329656,-0.7355874110218236,-0.863945285131992,-1.5893034651265248,0.9067187763119877,2.1291598317305915,-1.9204924957035332,-0.9009237402034631,-1.7346274966954778,1.0158782730879494]\n(9, 7) -> #1 [1.3225591582503364,-1.2389579239416575,1.4821870929647554,-1.0124405578731677,0.17335991461033706,0.3221085740556537,-0.2438014603760078,1.2404692413961085,-3.4084509689965516,2.3715993898012018]\n(9, 8) -> #1 [0.8563413627597283,-0.2370288833085772,0.3309561981130491,-0.9850541382142124,-1.3274331997767175,0.8603686512505615,-0.4089299077561886,1.5824467031330451,-1.3375667438043803,2.158626754346267]\n(9, 9) -> #1 [2.2451012485062405,-1.3202567018035034,2.8431493914647614,0.5908860141854642,-1.3275723771396097,-0.7712082904617317,-1.2250132130800644,0.7633993320235494,0.2529627294511647,-0.7067871657920524]\n\nimport scala.math.max\nnbRowSOM: Int = 10\nnbColSOM: Int = 10\nnbIter: Int = 30\ndataNbObs: Int = 2000\ndataNbVars: Int = 10\ndataNbCls: Int = 2\ndatas: org.apache.spark.rdd.RDD[NamedVector] = MapPartitionsRDD[1] at map at <console>:139\nstartLearningTime: Long = 1497431143931\nsom: SomTrainerA = SomTrainerA@502d9322\nsomOptions: scala.collection.immutable.Map[String,String] = Map(clustering.som.nbrow -> 10, clustering.som.nbcol -> 10)\nsomConvergeDist: Double = -0.1\nstartLearningTime: Long = 1497431143931\nmodel: AbstractModel =\n(0, 0) -> #1 [1.390677705912189,1.3740585164389065,0.6265104422009801,-0.7391539010366508,-1.0966525190993068,-2.1163540525925586,-1.100816338437808,-0.0648554675531714,-2.3660711385780155,1.8096766358427605]\n(0, 1) -> #0 [2.916317248527624,1.4850935399237892,0.10269368285..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":25,"time":"Took: 20 seconds 42 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"presentation":{"tabs_state":"{\n  \"tab_id\": \"#tab1830041141-0\"\n}","pivot_chart_state":"{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"},"id":"8AC0D862AE2E44BB87F55C13E655D5AF"},"cell_type":"code","source":"val dim = datas.take(1)(0).toArray.length   \nval header = \"# mapDim=2 mapSize={\"+ nbRowSOM +\",\" + nbColSOM + \"}\" + \n  \" pointDim=\" + dim + \" pointRealDim=\" + dim + \" mapMin={\" + Array.fill[Byte](dim)(0).mkString(\",\") + \"}\"\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"dim: Int = 10\nheader: String = # mapDim=2 mapSize={10,10} pointDim=10 pointRealDim=10 mapMin={0,0,0,0,0,0,0,0,0,0}\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":26,"time":"Took: 1 second 204 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"CAE0F06E43984FB7B9E0A5C18E99DCC8"},"cell_type":"code","source":"object Output extends Serializable {\n  def addHeaderToRdd(sparkCtx: SparkContext, lines: RDD[String], header: String): RDD[String] = {\n    val headerRDD = sparkCtx.parallelize(List((-1L, header)))     // index the header with -1, so that the sort will put it on top.\n    val pairRDD = lines.zipWithIndex()\n    val pairRDD2 = pairRDD.map(t => (t._2, t._1))\n    val allRDD = pairRDD2.union(headerRDD)\n    val allSortedRDD = allRDD.sortByKey()\n    return allSortedRDD.values\n  }\n  def write(outputDir: String) {\n      val dim = datas.take(1)(0).toArray.length\n      val mapMin = Array.fill[Byte](dim)(0).mkString(\",\")\n      var header = \"# mapDim=2 mapSize={\"+ nbRowSOM +\",\" + nbColSOM + \"}\"\n      header += \" pointDim=\" + dim + \" pointRealDim=\" + dim + \" mapMin={\" + mapMin + \"}\"\n    \n      val prototypes = model.prototypes.map(d => d._point)\n      println(\"Write Prototypes...\")\n      val protosString = sc.parallelize(prototypes).map(d => d.toArray.mkString(\",\"))\n      val protosResult = addHeaderToRdd(sc, protosString, header)\n      protosResult.coalesce(1).saveAsTextFile(outputDir+\"/maps\")\n\n      val sumAffectedDatas = datas.map(d => (model.findClosestPrototype(d).id, 1))\n        .reduceByKey{case (sum1, sum2) => sum1+sum2}\n        .collectAsMap() \n      val card = (0 to prototypes.length - 1).map(d => {\n        if (sumAffectedDatas.contains(d)) {\n          sumAffectedDatas(d)\n        } else {\n          0\n        }\n      })\n      println(\"Write Cardinalities...\")\n      var cardHeader = \"# mapDim=2 mapSize={\"+ nbRowSOM +\",\" + nbColSOM + \"}\" \n      cardHeader +=  \"pointDim=1 pointRealDim=0 mapMin={0} mapMax={0}\"\n      val cardRdd = sc.parallelize(card).map(d => \"\" + d)\n      val cardResult = addHeaderToRdd(sc, cardRdd, cardHeader)\n      cardResult.coalesce(1).saveAsTextFile(outputDir+\"/cards\")\n      \n    \n      val affHeader = \"# mapDim=1 mapSize={\" + datas.count() + \"} pointDim=1 pointRealDim=0 mapMin={0} mapMax={0}\"\n      val aff = datas.map(d => model.findClosestPrototype(d).id + \"\")\n      val affResult = addHeaderToRdd(sc, aff, affHeader)\n      println(\"Write Affiliate...\")\n      affResult.coalesce(1).saveAsTextFile(outputDir+\"/affs\")\n    \n      println(\"Write Maps...\")\n      val maps = sc.parallelize(prototypes.zip(card)).map(d => d._1.toArray.mkString(\",\") + \",\" + d._2)\n        .coalesce(1).saveAsTextFile(outputDir+\"/mapscard\")\n      println(\"Write successfully...\")\n  }\n}\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"defined object Output\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":27,"time":"Took: 1 second 639 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"81F586E364D7424B8BE69DDEB406C36D"},"cell_type":"code","source":"val outputDir = \"/Users/caoquan/output\"\nOutput.write(outputDir)","outputs":[{"name":"stdout","output_type":"stream","text":"Write Prototypes...\nWrite Cardinalities...\nWrite Affiliate...\nWrite Maps...\nWrite successfully...\noutputDir: String = /Users/caoquan/output\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":28,"time":"Took: 3 seconds 670 milliseconds, at 2017-6-14 11:5"}]},{"metadata":{"id":"3FBBA4C01B7948E3960B93E17B8EB19A"},"cell_type":"markdown","source":"#MTM"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"CF974265B6D5481E87519BE77BCE0E2E"},"cell_type":"code","source":"//package org.lipn.som.som\n\n/*import org.lipn.som.global.AbstractModel\nimport org.lipn.som.global.AbstractModel\nimport org.lipn.som.global.AbstractPrototype\nimport org.lipn.som.global.AbstractTrainer\nimport org.lipn.som.utils.NamedVector\nimport org.lipn.som.utils.DataGenerator\n*/\n\n\nobject RunMTM{\n  \n    def main(args:Array[String]) {\n      run(\n          sparkMaster = args(0),\n          intputFile = args(1),\n          outputDir = args(2),\n          execName = args(3),\n          nbRow = args(4).toInt,\n          nbCol = args(5).toInt,\n          tmin = args(6).toDouble,\n          tmax = args(7).toDouble,\n          convergeDist = args(8).toDouble,\n          maxIter = args(9).toInt,\n          sep = args(10),\n          initMap = args(11).toInt, //0: initialisation aleatoire\n          initMapFile = args(12)\n      )  \n    }\n  \n  def run(\n    sparkMaster: String,\n    intputFile: String,\n    outputDir: String,\n    execName: String = \"RunSom\",\n    nbRow: Int = 10, \n    nbCol: Int = 10, \n    tmin: Double = 0.9, \n    tmax: Double = 8,\n    convergeDist: Double = -0.001,\n\t\tmaxIter: Int = 50,\n\t\tsep : String = \";\",\n\t\tinitMap: Int = 0,\n\t\tinitMapFile : String = \"\",\n\t\tnbRealVars : Int = 10\n    ) = {\n    val sparkConf = new SparkConf().setAppName(execName)\n\t\tsparkConf.setMaster(sparkMaster)\n\t\tval sc = new SparkContext(sparkConf)\n\n    val somOptions = Map(\n    \t\t\"clustering.som.nbrow\" -> nbRow.toString, \n    \t\t\"clustering.som.nbcol\" -> nbCol.toString,\n    \t\t\"clustering.som.tmin\" -> tmin.toString,\n    \t\t\"clustering.som.tmax\" -> tmax.toString,\n    \t\t\"clustering.som.initMap\" -> initMap.toString,\n    \t\t\"clustering.som.initMapFile\" -> initMapFile.toString,   \n    \t\t\"clustering.som.separator\" -> sep.toString,\n        \"clustering.som.nbRealVars\" -> nbRealVars.toString\n    \t\t)\n\t    \t\n\t  val trainingDatasetId = sc.textFile(intputFile).map(x => new DenseVector(x.split(sep).map(_.toDouble))).cache() \n\t  \n\t  val trainingDataset = trainingDatasetId.map{ e =>\n//\t     new DenseVector(e.toArray.take(e.size - 1)) \n      \t new DenseVector(e.toArray.take(e.size)) \n\n\t  }.cache()\n\t    \n \n\t  println(s\"nbRow: ${trainingDataset.count()}\")\n\t    \t\t\n\t\tval model = trainingAndPrint(new SomTrainerA, trainingDataset, somOptions, maxIter, convergeDist)\n\t\tprint(\"le model est : \"+model)\n\t\tsc.parallelize(model.prototypes).saveAsTextFile(outputDir+\"/model\")\n\t    \t\n\t\t\n\t  // transformer un point de donnÃ©es en un objet contenant la donnÃ©es et son identifiant \n\t  val trainingDatasetObj = trainingDatasetId.map{ e =>\n\t    val dataPart = e.toArray.take(e.size - 1) // the last column represents the identifier\n\t    val id = e.toArray(e.size - 1).toInt\n\t    new pointObj(new DenseVector(dataPart), id)\n\t  }.cache()\n\t  \n\t  trainingDataset.unpersist(true) \n\t  \n\t\t//model.assign(trainingDatasetObj).saveAsTextFile(outputDir+\"/assignDatas\")\n\t\t\n//\t\tsc.stop()\n  }\n\n\n\tdef purity(model: AbstractModel, dataset: RDD[NamedVector]): Double = {\n\t\t\t//val nbRealClass = dataset.map(_.cls).reduce(case(cls1,cls2))\n\n\t\t\tval sumAffectedDatas = dataset.map(d => ((model.findClosestPrototype(d).id, d.cls), 1))\n\t\t\t\t\t.reduceByKey{case (sum1, sum2) => sum1+sum2}\n\n\t\t\tval maxByCluster = sumAffectedDatas.map(sa => (sa._1._1, sa._2))\n\t\t\t\t\t.reduceByKey{case (sum1, sum2) => sum1.max(sum2) }\n\t\t\t.map(_._2)\n\t\t\t.collect()\n\n\t\t\tmaxByCluster.sum / dataset.count().toDouble\n\t}\n\n\tdef trainingAndPrint(trainer: AbstractTrainer,\n\t\t\tdataset: RDD[DenseVector],\n\t\t\tmodelOptions: Map[String, String],\n\t\t\tmaxIteration: Int = 100,\n\t\t\tendConvergeDistance: Double): AbstractModel = {\n\t\t\tval model = trainer.training(dataset, modelOptions, maxIteration, endConvergeDistance)\n\t\t  // Initi  alisation du model\n\t\t\t//val trainer = new SomTrainer(nbRow, nbCol, trainingDataset, convergeDist, maxIter)\n\t\t\t//val model = trainer.model\n\n  \t\tprintln(\"-- Convergence Distance : \" + trainer.getLastConvergence)\n  \t\tprintln(\"-- NbIteration : \" + trainer.getLastIt)\n  \t\tprintln(\"-- Training duration : \" + trainer.getLastTrainingDuration)\n  \t\tprintln(\"-- The model : \" + model)\n  \t\t\n  \t\t\n  \t\tmodel\n\t}\n}\n\n","outputs":[{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":29,"time":"Took: 1 second 284 milliseconds, at 2017-6-14 11:6"}]}],"nbformat":4}